# -*- coding: utf-8 -*-
"""model_MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rD8_BiYmQi7aMc3I_GiFw1fUSiBjO6pf
"""

import torch
from torch import nn
import torch.nn.functional as F
import pandas as pd
from sklearn.model_selection import train_test_split

data = pd.read_csv('./parsed_dataset.csv')

data.pop('url')
data1 = data.copy()
label = data.pop('label').replace(-1,0).values
feature = data.values

x_train, x_test, y_train, y_test = train_test_split(
    feature, label, stratify = label, test_size=0.25, shuffle=True)

x_train = torch.Tensor(x_train)

x_test = torch.Tensor(x_test)

y_train = torch.Tensor(y_train)
y_train = torch.unsqueeze(y_train, 1)

y_test = torch.Tensor(y_test)
y_test = torch.unsqueeze(y_test, 1)

hidden_dim1 = 10
hidden_dim2 = 10
hidden_dim3 = 5
epochs = 2000
learning_rate = 0.001

class MLP(nn.Module):
  def __init__(self, feature_size, hidden1, hidden2, hidden3):
    super().__init__()

    self.feature = feature_size
    self.hidden_dim1 = hidden1
    self.hidden_dim2 = hidden2
    self.hidden_dim3 = hidden3

    self.layer1 = nn.Sequential(
        nn.Linear(self.feature, self.hidden_dim1),
        nn.ReLU()
    )
    self.layer2 = nn.Sequential(
        nn.Linear(self.hidden_dim1, self.hidden_dim2),
        nn.ReLU()
    )
    self.layer3 = nn.Sequential(
        nn.Linear(self.hidden_dim2, self.hidden_dim3),
        nn.ReLU()
    )
    self.output = nn.Sequential(
        nn.Linear(self.hidden_dim3, 1),
        nn.Sigmoid()
    )
  def forward(self, x):
    x = self.layer1(x)
    x = self.layer2(x)
    x = self.layer3(x)
    x = self.output(x)
    return x

  def accuracy_fn(self, x, y):
    result = x
    for i in range(len(result)):
      if result[i][0] >= 0.5:
        result[i][0] = 1
      else:
        result[i][0] = 0
    n_correct = torch.eq(result, y).sum().item()
    accuracy = (n_correct/len(x)) *100
    return accuracy

model = MLP(len(feature[0]), hidden_dim1, hidden_dim2, hidden_dim3)

import torch.optim as optim

loss = F.binary_cross_entropy
#loss = F.mse_loss

#optimizer = optim.SGD(model.parameters(), lr = learning_rate)
optimizer = optim.Adam(model.parameters(), lr = learning_rate)

for epoch in range(epochs):
  
  Hypothesis = model(x_train)
  cost = loss(Hypothesis, y_train)

  optimizer.zero_grad()
  cost.backward()
  optimizer.step()

  #--------------------------------------#
  if epoch%50 == 0:
    accuracy = model.accuracy_fn(Hypothesis.detach(), y_train)
    print(f"Epoch: {epoch}/{epochs}, loss: {cost:.2f}, accuracy: {accuracy:.1f}")
  #--------------------------------------#

accuracy = model.accuracy_fn(model(x_test), y_test)

accuracy

torch.save(model,'saved_model.pth')


